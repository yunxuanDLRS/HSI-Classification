{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1gbG95826S9RBFZjPAv23gCSL0h8zS3m2","authorship_tag":"ABX9TyNK1hxakE5TeS11Lippr+Ss"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIwPuqk9QsBD","executionInfo":{"status":"ok","timestamp":1670051065012,"user_tz":-480,"elapsed":4904,"user":{"displayName":"feyyy chow","userId":"01991168991301125311"}},"outputId":"3af15c07-3035-4d02-ee2f-0099b49efc39"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops\n","  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 548 kB/s \n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"pkbbkoyRPkXT","executionInfo":{"status":"ok","timestamp":1670051067579,"user_tz":-480,"elapsed":2572,"user":{"displayName":"feyyy chow","userId":"01991168991301125311"}}},"outputs":[],"source":["import PIL\n","import time\n","import torch\n","import torchvision\n","import torch.nn.functional as F\n","from einops import rearrange\n","from torch import nn\n","import torch.nn.init as init"]},{"cell_type":"code","source":["def _weights_init(m):\n","  classname = m.__class__.__name\n","  if isinstance(m,nn.Linear) or isinstance(m,nn.Conv3d):\n","    init.kaiming_normal(m.weight)\n","class Residual(nn.Module):\n","  def __init__(self,fn):\n","    super().init__()\n","    self.fn = fn\n","\n","class Residual(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        return self.fn(x, **kwargs) + x\n","# 等于 PreNorm\n","class LayerNormalize(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","# 等于 FeedForward\n","class MLP_Block(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout=0.1):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads=8, dropout=0.1):\n","        super().__init__()\n","        self.heads = heads\n","        self.scale = dim ** -0.5\n","        self.to_qkv = nn.Linear(dim,dim*3,bias=True)\n","        self.nn1 = nn.Linear(dim,dim)\n","        self.do1 = nn.Dropout(dropout)\n","    def forward(self,x,mask=None):\n","      b, n, _, h = *x.shape, self.heads\n","      qkv = self.to_qkv(x).chunk(3,dim=-1)\n","      q,k,v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)# split into multi head attentions\n","\n","      dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n","      mask_value = -torch.finfo(dots.dtype).max\n","      if mask is not None:\n","        mask = F.pad(mask.flatten(1), (1, 0), value=True)\n","        assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n","        mask = mask[:, None, :] * mask[:, :, None]\n","        dots.masked_fill_(~mask, float('-inf'))\n","        del mask\n","      attn = dots.softmax(dim=-1)\n","      out = torch.einsum('bhij,bhjd->bhid', attn, v)\n","      out = rearrange(out, 'b h n d -> b n (h d)')\n","      out = self.nn1(out)\n","      out = self.do1(out)\n","      return out\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, mlp_dim, dropout):\n","        super().__init__()\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Residual(LayerNormalize(dim, Attention(dim, heads=heads, dropout=dropout))),\n","                Residual(LayerNormalize(dim, MLP_Block(dim, mlp_dim, dropout=dropout)))\n","            ]))\n","\n","    def forward(self, x, mask=None):\n","        for attention, mlp in self.layers:\n","            x = attention(x, mask=mask)  # go to attention\n","            x = mlp(x)  # go to MLP_Block\n","        return x\n","\n","NUM_CLASS = 16\n","class SSFTTnet(nn.Module):\n","    def __init__(self, in_channels=1, num_classes=NUM_CLASS, num_tokens=4, dim=64, depth=1, heads=8, mlp_dim=8, dropout=0.1, emb_dropout=0.1):\n","      super(SSFTTnet, self).__init__()\n","      self.L = num_tokens  #即输入的影像数据经过EMBD转化为tokek的个数，在本实例中设为4\n","      self.ct = dim\n","      self.conv3d_features = nn.Sequential(\n","          nn.Conv3d(in_channels, out_channels=8, kernel_size=(3, 3, 3)),\n","          nn.BatchNorm3d(8),\n","          nn.ReLU(),\n","      )\n","      self.conv2d_features = nn.Sequential(\n","          nn.Conv2d(in_channels=8*28, out_channels=64, kernel_size=(3, 3)),\n","          nn.BatchNorm2d(64),\n","          nn.ReLU(), \n","      )\n","      # Tokenization\n","      self.token_wA = nn.Parameter(torch.empty(1,self.L,64),requires_grad=True)# Tokenization parameters (1,4,64)\n","      torch.nn.init.xavier_normal_(self.token_wA)\n","      self.token_wV = nn.Parameter(torch.empty(1,64,self.ct),requires_grad=True)# Tokenization parameters\n","      torch.nn.init.xavier_normal_(self.token_wV)\n","\n","      self.pos_embedding = nn.Parameter(torch.empty(1,(num_tokens+1),dim))\n","      torch.nn.init.normal_(self.pos_embedding, std=.02)\n","      self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))\n","      self.dropout = nn.Dropout(emb_dropout)\n","      self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)\n","      self.to_cls_token = nn.Identity()#???????????????????????\n","      self.nn1 = nn.Linear(dim, num_classes)\n","      torch.nn.init.xavier_uniform_(self.nn1.weight)\n","      torch.nn.init.normal_(self.nn1.bias, std=1e-6)\n","    def forward(self, x, mask=None):\n","      print(\"输入数据的x.shape:\",x.shape)\n","      #  A. Spectral–Spatial Feature Extraction\n","      x = self.conv3d_features(x)\n","      x = rearrange(x, 'b c h w y -> b (c h) w y')\n","      x = self.conv2d_features(x)\n","      x = rearrange(x,'b c h w -> b (h w) c')\n","      print(\"在卷积处理后的x.shape:\",x.shape)\n","\n","      #  将经过卷积处理的输入数据生成token!!!!!!!!!!!!!!!!\n","      wa = rearrange(self.token_wA, 'b h w -> b w h')#(1,64,4)\n","      print(\"wa.shape:\",wa.shape)\n","      A = torch.einsum('bij,bjk->bik', x, wa)\n","      print(\"A.shape:\",A.shape)\n","      A = rearrange(A, 'b h w -> b w h')  # Transpose\n","      print(\"after transpose A.shape:\",A.shape)\n","      A = A.softmax(dim=-1)\n","      print(\"after softmax A.shape:\",A.shape)\n","      VV = torch.einsum('bij,bjk->bik', x, self.token_wV)\n","      print(\"self.token_wV.shape:\",self.token_wV.shape)\n","      print(\"VV.shape:\",VV.shape)\n","      T = torch.einsum('bij,bjk->bik', A, VV)\n","      print(\"T.shape:\",T.shape)\n","      #print(\"T.shape:\",T.shape)\n","\n","      #主体传播\n","      cls_tokens = self.cls_token.expand(x.shape[0],-1,-1)\n","      print(\"after cls_tokens x.shape:\",cls_tokens.shape)\n","      x = torch.cat((cls_tokens, T), dim=1)\n","      print(\"after cat x.shape:\",x.shape)\n","      x += self.pos_embedding\n","      x = self.dropout(x)\n","      x = self.transformer(x, mask)  # main game\n","      x = self.to_cls_token(x[:, 0])\n","      x = self.nn1(x)\n","      return x"],"metadata":{"id":"wW27SBz2QzpK","executionInfo":{"status":"ok","timestamp":1670051587145,"user_tz":-480,"elapsed":662,"user":{"displayName":"feyyy chow","userId":"01991168991301125311"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    model = SSFTTnet()\n","    model.eval()\n","    #print(model)\n","    input = torch.randn(1, 1, 30, 13, 13)\n","    y = model(input)\n","    print(y.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxjaihNRkpfR","executionInfo":{"status":"ok","timestamp":1670051589854,"user_tz":-480,"elapsed":4,"user":{"displayName":"feyyy chow","userId":"01991168991301125311"}},"outputId":"2dac0691-f0b4-497c-e87c-8eae79fcb6ef"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["输入数据的x.shape: torch.Size([1, 1, 30, 13, 13])\n","在卷积处理后的x.shape: torch.Size([1, 81, 64])\n","wa.shape: torch.Size([1, 64, 4])\n","A.shape: torch.Size([1, 81, 4])\n","after transpose A.shape: torch.Size([1, 4, 81])\n","after softmax A.shape: torch.Size([1, 4, 81])\n","self.token_wV.shape: torch.Size([1, 64, 64])\n","VV.shape: torch.Size([1, 81, 64])\n","T.shape: torch.Size([1, 4, 64])\n","after cls_tokens x.shape: torch.Size([1, 1, 64])\n","after cat x.shape: torch.Size([1, 5, 64])\n","torch.Size([1, 16])\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import scipy.io as sio\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from operator import truediv\n","import time"],"metadata":{"id":"FOz62zEVqjpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#加载数据\n","def loadData():\n","    # 读入数据\n","    data = sio.loadmat('/content/drive/MyDrive/AI data/hyperspetral image/Indian_pines_corrected.mat')['indian_pines_corrected']\n","    labels = sio.loadmat('/content/drive/MyDrive/AI data/hyperspetral image/Indian_pines_gt.mat')['indian_pines_gt']\n","\n","    return data, labels\n","# 对高光谱数据 X 应用 PCA 变换\n","def applyPCA(X,numComponents):\n","  newX = np.reshape(X, (-1, X.shape[2]))\n","  pca = PCA(n_components=numComponents, whiten=True)\n","  newX = pca.fit_transform(newX)\n","  newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n","  return newX\n","\n","# 对单个像素周围提取 patch 时，边缘像素就无法取了，因此，给这部分像素进行 padding 操作\n","def padWithZeros(X, margin=2):\n","    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n","    x_offset = margin\n","    y_offset = margin\n","    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n","    return newX\n","\n","# 在每个像素周围提取 patch ，然后创建成符合 keras 处理的格式\n","def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n","\n","    # 给 X 做 padding\n","    margin = int((windowSize - 1) / 2)\n","    zeroPaddedX = padWithZeros(X, margin=margin)\n","    # split patches\n","    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n","    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n","    patchIndex = 0\n","    for r in range(margin, zeroPaddedX.shape[0] - margin):\n","        for c in range(margin, zeroPaddedX.shape[1] - margin):\n","            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n","            patchesData[patchIndex, :, :, :] = patch\n","            patchesLabels[patchIndex] = y[r-margin, c-margin]\n","            patchIndex = patchIndex + 1\n","    if removeZeroLabels:\n","        patchesData = patchesData[patchesLabels>0,:,:,:]\n","        patchesLabels = patchesLabels[patchesLabels>0]\n","        patchesLabels -= 1\n","    return patchesData,patchesLabels\n","\n","#划分数据集\n","def splitTrainTestSet(X, y, testRatio, randomState=345):\n","  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=testRatio,random_state=randomState,stratify=y)\n","  return X_train, X_test, y_train, y_test\n","\n","BATCH_SIZE_TRAIN = 64\n","def create_data_loader():\n","    # 地物类别\n","    # class_num = 16\n","    # 读入数据\n","    X, y = loadData()\n","    # 用于测试样本的比例\n","    test_ratio = 0.90\n","    # 每个像素周围提取 patch 的尺寸\n","    patch_size = 13\n","    # 使用 PCA 降维，得到主成分的数量\n","    pca_components = 30\n","\n","    print('Hyperspectral data shape: ', X.shape)\n","    print('Label shape: ', y.shape)\n","\n","    print('\\n... ... PCA tranformation ... ...')\n","    X_pca = applyPCA(X, numComponents=pca_components)\n","    print('Data shape after PCA: ', X_pca.shape)\n","\n","    print('\\n... ... create data cubes ... ...')\n","    X_pca, y_all = createImageCubes(X_pca, y, windowSize=patch_size)\n","    print('Data cube X shape: ', X_pca.shape)\n","    print('Data cube y shape: ', y.shape)\n","\n","    print('\\n... ... create train & test data ... ...')\n","    Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X_pca, y_all, test_ratio)\n","    print('Xtrain shape: ', Xtrain.shape)\n","    print('Xtest  shape: ', Xtest.shape)\n","\n","    # 改变 Xtrain, Ytrain 的形状，以符合 keras 的要求\n","    X = X_pca.reshape(-1, patch_size, patch_size, pca_components, 1)\n","    Xtrain = Xtrain.reshape(-1, patch_size, patch_size, pca_components, 1)\n","    Xtest = Xtest.reshape(-1, patch_size, patch_size, pca_components, 1)\n","    print('before transpose: Xtrain shape: ', Xtrain.shape)\n","    print('before transpose: Xtest  shape: ', Xtest.shape)\n","\n","    # 为了适应 pytorch 结构，数据要做 transpose\n","    X = X.transpose(0, 4, 3, 1, 2)\n","    Xtrain = Xtrain.transpose(0, 4, 3, 1, 2)\n","    Xtest = Xtest.transpose(0, 4, 3, 1, 2)\n","    print('after transpose: Xtrain shape: ', Xtrain.shape)\n","    print('after transpose: Xtest  shape: ', Xtest.shape)\n","\n","    # 创建train_loader和 test_loader\n","    X = TestDS(X, y_all)\n","    trainset = TrainDS(Xtrain, ytrain)\n","    testset = TestDS(Xtest, ytest)\n","    train_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=BATCH_SIZE_TRAIN,shuffle=True,num_workers=0)\n","    test_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=BATCH_SIZE_TRAIN,shuffle=True,num_workers=0)\n","    all_data_loader = torch.utils.data.DataLoader(dataset=X,batch_size=BATCH_SIZE_TRAIN,shuffle=False,num_workers=0)\n","    return train_loader, test_loader, all_data_loader, y\n","\n","#Training dataset\n","class TrainDS(torch.utils.data.Dataset):\n","  def __init__(self,Xtrain,ytrain):\n","    super().__init__()\n","    self.len = Xtrain.shape[0]\n","    self.x_data = torch.FloatTensor(Xtrain)\n","    self.y_data = torch.LongTensor(ytrain)\n","  def __getitem__(self,index):\n","    #根据索引返回数据和对应的标签\n","    return self.x_data[index], self.y_data[index]\n","  def __len__(self):\n","    #返回文件数\n","    return self.len\n","\"\"\" Testing dataset\"\"\"\n","class TestDS(torch.utils.data.Dataset):\n","    def __init__(self, Xtest, ytest):\n","        super().__init__()\n","        self.len = Xtest.shape[0]\n","        self.x_data = torch.FloatTensor(Xtest)\n","        self.y_data = torch.LongTensor(ytest)\n","    def __getitem__(self, index):\n","        # 根据索引返回数据和对应的标签\n","        return self.x_data[index], self.y_data[index]\n","    def __len__(self):\n","        # 返回文件数据的数目\n","        return self.len\n","\n","# 使用GPU训练\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","def train(train_loader,epochs):\n","  # 网络放到GPU上\n","  net = SSFTTnet().to(device)\n","  # 交叉熵损失函数\n","  criterion = nn.CrossEntropyLoss()\n","  # 初始化优化器\n","  optimizer = optim.Adam(net.parameters(), lr=0.001)\n","  # 开始训练\n","  total_loss = 0\n","  for epoch in range(epochs):\n","    net.train()\n","    for i,(data,target) in enumerate(train_loader):\n","      data, target = data.to(device), target.to(device)\n","      outputs = net(data)\n","      loss = criterion(outputs,target)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      total_loss += loss.item()\n","    print('[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]' % (epoch + 1, total_loss / (epoch + 1),loss.item()))\n","  print('Finished Training')\n","  return net, device\n","\n","def test(device, net, test_loader):\n","  count = 0\n","  net.eval()\n","  y_pred_test= 0\n","  y_test = 0\n","  for inputs,labels in test_loader:\n","    inputs = inputs.to(device)\n","    outputs = net(inputs)\n","    outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n","    if count == 0:\n","      y_pred_test = outputs\n","      y_test = labels\n","      count = 1\n","    else:\n","      y_pred_test = np.concatenate((y_pred_test, outputs))\n","      y_test = np.concatenate((y_test, labels))\n","  return y_pred_test, y_test\n","\n","def AA_andEachClassAccuracy(confusion_matrix):\n","  list_diag = np.diag(confusion_matrix)\n","  list_raw_sum = np.sum(confusion_matrix, axis=1)\n","  each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n","  average_acc = np.mean(each_acc)\n","  return each_acc, average_acc\n","\n","def acc_reports(y_test, y_pred_test):\n","  target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n","        , 'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',\n","                    'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n","                    'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n","                    'Stone-Steel-Towers']\n","  classification = classification_report(y_test, y_pred_test, digits=4, target_names=target_names)\n","  oa = accuracy_score(y_test, y_pred_test)\n","  confusion = confusion_matrix(y_test, y_pred_test)\n","  each_acc, aa = AA_andEachClassAccuracy(confusion)\n","  kappa = cohen_kappa_score(y_test, y_pred_test)\n","  return classification, oa*100, confusion, each_acc*100, aa*100, kappa*100\n","\n","if __name__ == '__main__':\n","  train_loader, test_loader, all_data_loader, y_all= create_data_loader()\n","  tic1 = time.perf_counter()\n","  net, device = train(train_loader, epochs=100)\n","  # 只保存模型参数\n","  torch.save(net.state_dict(), 'SSFTTnet_params.pth')\n","  toc1 = time.perf_counter()\n","  tic2 = time.perf_counter()\n","  y_pred_test, y_test = test(device, net, test_loader)\n","  toc2 = time.perf_counter()\n","  # 评价指标\n","  classification, oa, confusion, each_acc, aa, kappa = acc_reports(y_test, y_pred_test)\n","  classification = str(classification)\n","  Training_Time = toc1 - tic1\n","  Test_time = toc2 - tic2\n","  file_name = \"/content/drive/MyDrive/AI data/classification_report.txt\"\n","  with open(file_name, 'w') as x_file:\n","    x_file.write('{} Training_Time (s)'.format(Training_Time))\n","    x_file.write('\\n')\n","    x_file.write('{} Test_time (s)'.format(Test_time))\n","    x_file.write('\\n')\n","    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n","    x_file.write('\\n')\n","    x_file.write('{} Overall accuracy (%)'.format(oa))\n","    x_file.write('\\n')\n","    x_file.write('{} Average accuracy (%)'.format(aa))\n","    x_file.write('\\n')\n","    x_file.write('{} Each accuracy (%)'.format(each_acc))\n","    x_file.write('\\n')\n","    x_file.write('{}'.format(classification))\n","    x_file.write('\\n')\n","    x_file.write('{}'.format(confusion))\n","  get_cls_map=get_cls_map(net, device, all_data_loader, y_all)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Of8q2LwHqzRJ","executionInfo":{"status":"ok","timestamp":1668775087262,"user_tz":-480,"elapsed":18464,"user":{"displayName":"feyyy chow","userId":"01991168991301125311"}},"outputId":"1e2fa2cd-8d6f-4a22-b2a0-900a1ad4afbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hyperspectral data shape:  (145, 145, 200)\n","Label shape:  (145, 145)\n","\n","... ... PCA tranformation ... ...\n","Data shape after PCA:  (145, 145, 30)\n","\n","... ... create data cubes ... ...\n","Data cube X shape:  (10249, 13, 13, 30)\n","Data cube y shape:  (145, 145)\n","\n","... ... create train & test data ... ...\n","Xtrain shape:  (1024, 13, 13, 30)\n","Xtest  shape:  (9225, 13, 13, 30)\n","before transpose: Xtrain shape:  (1024, 13, 13, 30, 1)\n","before transpose: Xtest  shape:  (9225, 13, 13, 30, 1)\n","after transpose: Xtrain shape:  (1024, 1, 30, 13, 13)\n","after transpose: Xtest  shape:  (9225, 1, 30, 13, 13)\n","[Epoch: 1]   [loss avg: 29.0866]   [current loss: 1.2049]\n","[Epoch: 2]   [loss avg: 20.6221]   [current loss: 0.3940]\n","[Epoch: 3]   [loss avg: 15.4728]   [current loss: 0.4008]\n","[Epoch: 4]   [loss avg: 12.3181]   [current loss: 0.0614]\n","[Epoch: 5]   [loss avg: 10.3240]   [current loss: 0.0578]\n","[Epoch: 6]   [loss avg: 8.8709]   [current loss: 0.0615]\n","[Epoch: 7]   [loss avg: 7.7232]   [current loss: 0.0624]\n","[Epoch: 8]   [loss avg: 6.8260]   [current loss: 0.0441]\n","[Epoch: 9]   [loss avg: 6.1134]   [current loss: 0.0231]\n","[Epoch: 10]   [loss avg: 5.5741]   [current loss: 0.0333]\n","[Epoch: 11]   [loss avg: 5.1249]   [current loss: 0.0544]\n","[Epoch: 12]   [loss avg: 4.7334]   [current loss: 0.0065]\n","[Epoch: 13]   [loss avg: 4.3853]   [current loss: 0.0141]\n","[Epoch: 14]   [loss avg: 4.0905]   [current loss: 0.0216]\n","[Epoch: 15]   [loss avg: 3.8246]   [current loss: 0.0068]\n","[Epoch: 16]   [loss avg: 3.5893]   [current loss: 0.0018]\n","[Epoch: 17]   [loss avg: 3.3816]   [current loss: 0.0088]\n","[Epoch: 18]   [loss avg: 3.1963]   [current loss: 0.0016]\n","[Epoch: 19]   [loss avg: 3.0305]   [current loss: 0.0014]\n","[Epoch: 20]   [loss avg: 2.8806]   [current loss: 0.0008]\n","[Epoch: 21]   [loss avg: 2.7449]   [current loss: 0.0011]\n","[Epoch: 22]   [loss avg: 2.6211]   [current loss: 0.0021]\n","[Epoch: 23]   [loss avg: 2.5081]   [current loss: 0.0012]\n","[Epoch: 24]   [loss avg: 2.4053]   [current loss: 0.0016]\n","[Epoch: 25]   [loss avg: 2.3149]   [current loss: 0.0064]\n","[Epoch: 26]   [loss avg: 2.2633]   [current loss: 0.0264]\n","[Epoch: 27]   [loss avg: 2.2389]   [current loss: 0.0360]\n","[Epoch: 28]   [loss avg: 2.1995]   [current loss: 0.0414]\n","[Epoch: 29]   [loss avg: 2.1537]   [current loss: 0.0228]\n","[Epoch: 30]   [loss avg: 2.1042]   [current loss: 0.0222]\n","[Epoch: 31]   [loss avg: 2.0404]   [current loss: 0.0074]\n","[Epoch: 32]   [loss avg: 1.9793]   [current loss: 0.0057]\n","[Epoch: 33]   [loss avg: 1.9207]   [current loss: 0.0015]\n","[Epoch: 34]   [loss avg: 1.8653]   [current loss: 0.0007]\n","[Epoch: 35]   [loss avg: 1.8126]   [current loss: 0.0011]\n","[Epoch: 36]   [loss avg: 1.7628]   [current loss: 0.0029]\n","[Epoch: 37]   [loss avg: 1.7155]   [current loss: 0.0004]\n","[Epoch: 38]   [loss avg: 1.6708]   [current loss: 0.0012]\n","[Epoch: 39]   [loss avg: 1.6283]   [current loss: 0.0013]\n","[Epoch: 40]   [loss avg: 1.5878]   [current loss: 0.0006]\n","[Epoch: 41]   [loss avg: 1.5493]   [current loss: 0.0009]\n","[Epoch: 42]   [loss avg: 1.5128]   [current loss: 0.0005]\n","[Epoch: 43]   [loss avg: 1.4779]   [current loss: 0.0009]\n","[Epoch: 44]   [loss avg: 1.4445]   [current loss: 0.0008]\n","[Epoch: 45]   [loss avg: 1.4126]   [current loss: 0.0004]\n","[Epoch: 46]   [loss avg: 1.3821]   [current loss: 0.0003]\n","[Epoch: 47]   [loss avg: 1.3528]   [current loss: 0.0007]\n","[Epoch: 48]   [loss avg: 1.3248]   [current loss: 0.0006]\n","[Epoch: 49]   [loss avg: 1.2979]   [current loss: 0.0007]\n","[Epoch: 50]   [loss avg: 1.2721]   [current loss: 0.0003]\n","[Epoch: 51]   [loss avg: 1.2473]   [current loss: 0.0002]\n","[Epoch: 52]   [loss avg: 1.2243]   [current loss: 0.0005]\n","[Epoch: 53]   [loss avg: 1.2045]   [current loss: 0.0009]\n","[Epoch: 54]   [loss avg: 1.1836]   [current loss: 0.0010]\n","[Epoch: 55]   [loss avg: 1.1637]   [current loss: 0.0021]\n","[Epoch: 56]   [loss avg: 1.1437]   [current loss: 0.0018]\n","[Epoch: 57]   [loss avg: 1.1239]   [current loss: 0.0004]\n","[Epoch: 58]   [loss avg: 1.1047]   [current loss: 0.0004]\n","[Epoch: 59]   [loss avg: 1.0861]   [current loss: 0.0003]\n","[Epoch: 60]   [loss avg: 1.0681]   [current loss: 0.0002]\n","[Epoch: 61]   [loss avg: 1.0507]   [current loss: 0.0001]\n","[Epoch: 62]   [loss avg: 1.0338]   [current loss: 0.0003]\n","[Epoch: 63]   [loss avg: 1.0175]   [current loss: 0.0009]\n","[Epoch: 64]   [loss avg: 1.0017]   [current loss: 0.0002]\n","[Epoch: 65]   [loss avg: 0.9864]   [current loss: 0.0003]\n","[Epoch: 66]   [loss avg: 0.9715]   [current loss: 0.0002]\n","[Epoch: 67]   [loss avg: 0.9570]   [current loss: 0.0003]\n","[Epoch: 68]   [loss avg: 0.9430]   [current loss: 0.0003]\n","[Epoch: 69]   [loss avg: 0.9294]   [current loss: 0.0001]\n","[Epoch: 70]   [loss avg: 0.9162]   [current loss: 0.0001]\n","[Epoch: 71]   [loss avg: 0.9033]   [current loss: 0.0003]\n","[Epoch: 72]   [loss avg: 0.8908]   [current loss: 0.0001]\n","[Epoch: 73]   [loss avg: 0.8786]   [current loss: 0.0002]\n","[Epoch: 74]   [loss avg: 0.8668]   [current loss: 0.0002]\n","[Epoch: 75]   [loss avg: 0.8553]   [current loss: 0.0001]\n","[Epoch: 76]   [loss avg: 0.8441]   [current loss: 0.0002]\n","[Epoch: 77]   [loss avg: 0.8331]   [current loss: 0.0004]\n","[Epoch: 78]   [loss avg: 0.8225]   [current loss: 0.0001]\n","[Epoch: 79]   [loss avg: 0.8121]   [current loss: 0.0002]\n","[Epoch: 80]   [loss avg: 0.8020]   [current loss: 0.0001]\n","[Epoch: 81]   [loss avg: 0.7921]   [current loss: 0.0002]\n","[Epoch: 82]   [loss avg: 0.7825]   [current loss: 0.0001]\n","[Epoch: 83]   [loss avg: 0.7731]   [current loss: 0.0004]\n","[Epoch: 84]   [loss avg: 0.7639]   [current loss: 0.0001]\n","[Epoch: 85]   [loss avg: 0.7550]   [current loss: 0.0001]\n","[Epoch: 86]   [loss avg: 0.7462]   [current loss: 0.0002]\n","[Epoch: 87]   [loss avg: 0.7377]   [current loss: 0.0002]\n","[Epoch: 88]   [loss avg: 0.7293]   [current loss: 0.0001]\n","[Epoch: 89]   [loss avg: 0.7212]   [current loss: 0.0001]\n","[Epoch: 90]   [loss avg: 0.7132]   [current loss: 0.0000]\n","[Epoch: 91]   [loss avg: 0.7054]   [current loss: 0.0001]\n","[Epoch: 92]   [loss avg: 0.6977]   [current loss: 0.0001]\n","[Epoch: 93]   [loss avg: 0.6902]   [current loss: 0.0002]\n","[Epoch: 94]   [loss avg: 0.6829]   [current loss: 0.0000]\n","[Epoch: 95]   [loss avg: 0.6757]   [current loss: 0.0001]\n","[Epoch: 96]   [loss avg: 0.6687]   [current loss: 0.0001]\n","[Epoch: 97]   [loss avg: 0.6618]   [current loss: 0.0001]\n","[Epoch: 98]   [loss avg: 0.6551]   [current loss: 0.0000]\n","[Epoch: 99]   [loss avg: 0.6485]   [current loss: 0.0002]\n","[Epoch: 100]   [loss avg: 0.6420]   [current loss: 0.0001]\n","Finished Training\n","------Get classification maps successful-------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 69.6x69.6 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 69.6x69.6 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 69.6x69.6 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","def get_classification_map(y_pred, y):\n","  height = y.shape[0]\n","  width = y.shape[1]\n","  k = 0\n","  cls_labels = np.zeros((height, width))\n","  for i in range(height):\n","    for j in range(width):\n","      target = int(y[i,j])\n","      if target == 0:\n","        continue\n","      else:\n","        cls_labels[i][j] = y_pred[k]+1\n","        k += 1\n","  return cls_labels\n","\n","def list_to_colormap(x_list):\n","    y = np.zeros((x_list.shape[0], 3))\n","    for index, item in enumerate(x_list):\n","        if item == 0:\n","            y[index] = np.array([0, 0, 0]) / 255.\n","        if item == 1:\n","            y[index] = np.array([147, 67, 46]) / 255.\n","        if item == 2:\n","            y[index] = np.array([0, 0, 255]) / 255.\n","        if item == 3:\n","            y[index] = np.array([255, 100, 0]) / 255.\n","        if item == 4:\n","            y[index] = np.array([0, 255, 123]) / 255.\n","        if item == 5:\n","            y[index] = np.array([164, 75, 155]) / 255.\n","        if item == 6:\n","            y[index] = np.array([101, 174, 255]) / 255.\n","        if item == 7:\n","            y[index] = np.array([118, 254, 172]) / 255.\n","        if item == 8:\n","            y[index] = np.array([60, 91, 112]) / 255.\n","        if item == 9:\n","            y[index] = np.array([255, 255, 0]) / 255.\n","        if item == 10:\n","            y[index] = np.array([255, 255, 125]) / 255.\n","        if item == 11:\n","            y[index] = np.array([255, 0, 255]) / 255.\n","        if item == 12:\n","            y[index] = np.array([100, 0, 255]) / 255.\n","        if item == 13:\n","            y[index] = np.array([0, 172, 254]) / 255.\n","        if item == 14:\n","            y[index] = np.array([0, 255, 0]) / 255.\n","        if item == 15:\n","            y[index] = np.array([171, 175, 80]) / 255.\n","        if item == 16:\n","            y[index] = np.array([101, 193, 60]) / 255.\n","\n","    return y\n","def classification_map(map,ground_truth,dpi,save_path):\n","  fig = plt.figure(frameon=False)\n","  fig.set_size_inches(ground_truth.shape[1]*2.0/dpi, ground_truth.shape[0]*2.0/dpi)\n","  ax = plt.Axes(fig, [0., 0., 1., 1.])\n","  ax.set_axis_off()\n","  ax.xaxis.set_visible(False)\n","  ax.yaxis.set_visible(False)\n","  fig.add_axes(ax)\n","  ax.imshow(map)\n","  fig.savefig(save_path, dpi=dpi)\n","  return 0\n","def test(device, net, test_loader):\n","    count = 0\n","    # 模型测试\n","    net.eval()\n","    y_pred_test = 0\n","    y_test = 0\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        outputs = net(inputs)\n","        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n","        if count == 0:\n","            y_pred_test = outputs\n","            y_test = labels\n","            count = 1\n","        else:\n","            y_pred_test = np.concatenate((y_pred_test, outputs))\n","            y_test = np.concatenate((y_test, labels))\n","\n","    return y_pred_test, y_test\n","\n","def get_cls_map(net,device,all_data_loader,y):\n","  y_pred, y_new = test(device, net, all_data_loader)\n","  cls_labels = get_classification_map(y_pred, y)\n","  x = np.ravel(cls_labels)\n","  gt = y.flatten()\n","  y_list = list_to_colormap(x)\n","  y_gt = list_to_colormap(gt)\n","  y_re = np.reshape(y_list, (y.shape[0], y.shape[1], 3))\n","  gt_re = np.reshape(y_gt, (y.shape[0], y.shape[1], 3))\n","  classification_map(y_re,y,300,'/content/drive/MyDrive/AI data/classification_maps/' + 'IP_predictions.eps')\n","  classification_map(y_re, y, 300,'/content/drive/MyDrive/AI data/classification_maps/' + 'IP_predictions.png')\n","  classification_map(gt_re, y, 300,'/content/drive/MyDrive/AI data/classification_maps/' + 'IP_gt.png')\n","  print('------Get classification maps successful-------')"],"metadata":{"id":"HK6YsXaay2EL"},"execution_count":null,"outputs":[]}]}